# Ollama 项目进展报告

## 时间周期：2024-10-20 至 2024-10-27

------

### 修复的主要问题

1. **HTTP 500 错误**
   - **严重性:** 高
   - **描述:** 修复了 HTTP 生成 API 的问题，导致在固定的一分钟时间框架内返回 500 错误代码 ([#7373](https://github.com/ollama/ollama/issues/7373))。
2. **Unicode 输出问题**
   - **严重性:** 中
   - **描述:** 修复了在 Windows 系统上重定向文件时的 Unicode 输出问题，确保在使用重定向时输出正确的字符 ([#7358](https://github.com/ollama/ollama/issues/7358))。
3. **GPU 支持**
   - **严重性:** 中
   - **描述:** 解决了 Ollama 在 0.4.0-rc5-rocm 版本上无法运行在 GPU 上的问题 ([#7346](https://github.com/ollama/ollama/issues/7346))。

------

### 新增功能与性能增强

1. **大模型支持**
   - **新增特性:** 引入 AirLLM 或类似功能，允许在内存不足的情况下运行大型模型 ([#7366](https://github.com/ollama/ollama/issues/7366))。
2. **API 改进**
   - **新增功能:** 在聊天端点添加了 "prefix" 选项，提升 API 的灵活性与功能 ([#7342](https://github.com/ollama/ollama/issues/7342))。
3. **依赖获取逻辑优化**
   - **性能增强:** 改进了依赖项收集逻辑，增强了项目构建和依赖管理的稳定性 ([#7345](https://github.com/ollama/ollama/issues/7345))。
4. **性能问题解决**
   - **功能增强:** 修复了 8B+ 模型在 Windows Radeon 系统上的性能下降问题，改善用户体验 ([#7328](https://github.com/ollama/ollama/issues/7328))。

------

### 不兼容的系统改变

1. **版本更新**
   - **影响:** 更新到最新的 Go 1.22 补丁版本，可能导致与旧版本的兼容性问题，需要用户注意可能的调整 ([#7379](https://github.com/ollama/ollama/issues/7379))。
2. **模型加载重复限制**
   - **影响:** 新增支持同一模型多次加载的功能，可能与之前的实现产生不兼容，需要用户根据新逻辑调整代码 ([#7321](https://github.com/ollama/ollama/issues/7321))。
3. **深度模型支持的变更**
   - **影响:** 实现了对 LLaMA-Omni 的支持，可能与现有功能产生冲突，用户需要查看说明进行相应更新 ([#7319](https://github.com/ollama/ollama/issues/7319))。

------

如需获取更详细的信息，请访问 [Ollama GitHub 页面](https://github.com/ollama/ollama)。